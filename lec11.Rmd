---
title: "Эконометрика, Осень 2021"
subtitle: "Лекция 11.</br>Модли бинарного выбора: продолжение"
author: "Владимир Пырлик"
date: "Ноябрь 2021"
output:
  xaringan::moon_reader:
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    lib_dir: libs
    css: [libs/main.css, libs/fonts.css, libs/animate.css]
    chakra: libs/remark-latest.min.js
    nature:
      highlightStyle: github
      countIncrementalSlides: false
      highlightLines: true
      ratio: "8:5"
---
class: animated, fadeIn
## Модель бинарного выбора: общая постановка

Зависимая переменная - банарный "статус"

$$y_i\in\{0,\;1\}$$

Объясняющие переменные - привычный нам набор $k+1$ переменных

$$x_i=(1\;\;x_{i1}\;\;x_{i2}\;\;...\;\;x_{ik})'$$

--

Объект моделирвоания - всё условное распределение

$$y_i|x_i\sim G(x_i;\beta)$$

--

$$G(x;\beta)=\mathbb{P}\{y_i=1|x_i=x\}$$

---
class: animated, fadeIn
## Модель бинарного выбора: **модели линейного индекса**

$$y_i\in\{0,\;1\},\;x_i=(1\;\;x_{i1}\;\;...\;\;x_{ik})'$$

$$G(x;\beta)=\mathbb{P}\{y_i=1|x_i=x\}$$
$$\mathbb{P}\{y_i=1|x_i=x\}=G(\color{blue}{x'\beta})=G(\color{blue}{\beta_o+\beta_1x_1+...\beta_kx_k})$$

--

Варианты:

 - модель линейной вероятности: $G(\color{blue}{z})=\max(0;\;\min(\color{blue}{z};\;1))$

--

 - бинарный пробит: $G(\color{blue}{z})=\Phi_{0,1}(\color{blue}{z})$
 
 - бинарный логит: $G(\color{blue}{z})=\frac{\exp(\color{blue}{z})}{1-\exp(\color{blue}{z})}$

---
class: section, animated, fadeIn
## Модель бинарного выбора:</br>интересные свойства

---
class: hands, middle, animated, zoomIn
# .gb[?] 

## Достаточно ли модели веротяности $y_i=1$,
## чтобы говорить о модели
## *всего условного распределения?*

---
class: animated, fadeIn
## Модели бинарного выбора: **интересные свойства**

- $y_i|x_i$ - всегда **распределение Бернулли**

|*y*|0|1|
|:-:|:-:|:-:|
|*P*|*1-G(z)*|*G(z)*|

---
class: hands, middle, animated, zoomIn
# .gb[?] 

## Если мы моделируем все распределение,
## что можно о нем сказать?

---
class: animated, fadeIn
## Модели бинарного выбора: **интересные свойства**

- $y_i|x_i$ - всегда **распределение Бернулли**

|*y*|0|1|
|:-:|:-:|:-:|
|*P*|*1-G(z)*|*G(z)*|

- условные моменты $y_i$:

$$\mathbb{E}[y_i|x_i]=...=G(x_i;\beta)$$

$$\text{Var}[y_i|x_i]=...=G(x_i;\beta)\cdot\big(1-G(x_i;\beta)\big)$$

---
class: hands, middle, animated, zoomIn
# .gb[?] 

## Если известны условные моменты,
## разве мы не можем записать модель,
## как **регрессию в среднем?**

---
class: animated, fadeIn
## Модели бинарного выбора: **интересные свойства**

- $y_i|x_i$ - всегда **распределение Бернулли**

|*y*|0|1|
|:-:|:-:|:-:|
|*P*|*1-G(z)*|*G(z)*|

- условные моменты $y_i$:

$$\mathbb{E}[y_i|x_i]=...=G(x_i;\beta)$$

$$\text{Var}[y_i|x_i]=...=G(x_i;\beta)\cdot\big(1-G(x_i;\beta)\big)$$

- представление в виде регрессии в среднем:

$$y_i\;=\;G(x_i;\beta)\;+\;u_i,\;\mathbb{E}[u_i|x_i]=0.$$

---
class: section, animated, fadeIn
# Оценивание моделей</br>бинарного выбора

---
class: animated, fadeIn
## Нелинейный МНК

$$y_i\;=\;G(x_i'\beta)\;+\;u_i,\;\mathbb{E}[u_i|x_i]=0$$
$$\text{Var}[u_i|x_i]=G(x_i'\beta)\cdot\big(1-G(x_i'\beta)\big)$$

--

- из-за возможности представления в виде регресии в среднем, применим **нелинейный метод наименьших квадратов**

--

- оценки будут состоятельными

--

- неплохая оценка матрицы ковариаций оценок параметров .right[.rmk[(но все равно так себе)]]

--

- оценки будут не такими уж точными, редко используется

---
class: animated, fadeIn
## Метод минимальной перекретсной энтропии

|*y*|0|1|
|:-:|:-:|:-:|
|*P*|*1-G(z)*|*G(z)*|

- **"перекрестная энтропия"** - это одна из мер различия двух *распределений*

- мы хотим сравнить **фактическое распределение** и "модельное" (прогнозное) распределение величины $y_i|x_i$

--

$$H(D_o,\hat D)=-\mathbb{E}_{D_o}\log f_{\hat D}$$

--

.bb[?] Почему именно такая мера?

---
class: animated, fadeIn
## Перекрестная энтропия

$$H(D_o,\hat D)=-\mathbb{E}_{D_o}\log f_{\hat D}$$

.bb[?] Почему именно такая мера?

.rb[!] Задача минимизации популяционной перекрестной энтропии имеет единственное решение - истинное распределение. Мы применяем метод аналогии и получаем сосятотельную оценку всего распределения.

--

.rb[!] Оценки будут асимптотически эффективными

---
class: animated, fadeIn
## Метод минимальной перекретсной энтропии

|*y*|0|1|
|:-:|:-:|:-:|
|*P*|*1-G(z)*|*G(z)*|

- **"относительная энтропия"** - это одна из мер различия двух *распределений*

- мы хотим сравнить **фактическое распределение** и "модельное" (прогнозное) распределение величины $y_i|x_i$


$$H(D_o,\hat D)=-\mathbb{E}_{D_o}\log f_{\hat D} = ...$$
$$...\;=\;\begin{cases}-\log G(x_i'\beta),\;\text{если }y_i=1,\\-\log(1-G(x_i'\beta)),\;\text{если }y_i=0.\end{cases}$$

---
class: animated, fadeIn
## Метод минимальной относительной энтропии

$$\hat\beta=\arg\min_{b}\:-\sum_{i=1}^n\big[y_i\cdot\log G(x_i'b)+(1-y_i)\cdot\log\big(1-G(x_i'b)\big)\big]$$

--

.gb[!] Также известен, как **метод максимального правдоподобия**

--

.gb[!] Легко обобщается на случай задач множественного выбора

--

.gb[!] Достигнутая энтропия - естественная метрика качества модели .right[.rmk[особенно в прогнозном контексте]]

.gb[!] На основе перекретсной энтропии можно сравнивать даже разные модели бинарного выбора (для одного набора данных)

--

.rb[!] Рассчет $\hat V_{\hat\beta}$ требует определенного навыка...

---
class: animated, fadeIn
## 

---
class: animated, fadeIn
## 

